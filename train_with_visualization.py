#!/usr/bin/env python3
"""
UR10e Trajectory Tracking Training with Real-time Visualization
å¸¦å®æ—¶å¯è§†åŒ–çš„è®­ç»ƒè„šæœ¬
"""

import os
import sys

# Set CUDA device before importing Isaac Gym
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# Isaac Gym imports MUST be before any PyTorch imports
try:
    from isaacgym import gymapi
    from isaacgym import gymtorch
    from isaacgym import gymutil
    from isaacgym.torch_utils import *
    print("âœ… All Isaac Gym modules imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import Isaac Gym: {e}")
    sys.exit(1)

import numpy as np
import torch
import torch.nn as nn
import yaml
import time
from datetime import datetime
from typing import Dict, List, Tuple

# Stable-Baselines3 imports
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor

# Local imports
from ur10e_trajectory_env import UR10eTrajectoryEnv
from visualization_tool import TrajectoryVisualizer


class VisualizationCallback(BaseCallback):
    """å¸¦å¯è§†åŒ–çš„è®­ç»ƒå›è°ƒå‡½æ•°"""

    def __init__(self, visualizer, eval_freq: int = 5000, verbose: int = 1):
        super().__init__(verbose)
        self.visualizer = visualizer
        self.eval_freq = eval_freq
        self.training_trajectories = []
        self.start_time = time.time()
        self.last_viz_time = self.start_time
        self.best_mean_reward = -np.inf

    def _on_step(self) -> bool:
        current_time = time.time()

        # æ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if current_time - self.last_viz_time > 10.0:
            elapsed = current_time - self.start_time
            progress = (self.num_timesteps / self.training_total_timesteps) * 100

            print(f"ğŸ¨ è®­ç»ƒå¯è§†åŒ–æ›´æ–°:")
            print(f"   ğŸ“Š è¿›åº¦: {progress:.1f}% | æ­¥æ•°: {self.num_timesteps:,}")
            print(f"   â±ï¸  å·²è®­ç»ƒ: {elapsed/60:.1f}åˆ†é’Ÿ")
            print(f"   ğŸ”¥ å¹³å‡å¥–åŠ±: {getattr(self, 'current_mean_reward', 'N/A')}")

            self.last_viz_time = current_time

        # å®šæœŸè¯„ä¼°å’Œå¯è§†åŒ–
        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:
            self._evaluate_and_visualize()

        return True

    def _evaluate_and_visualize(self):
        """è¯„ä¼°å½“å‰ç­–ç•¥å¹¶å¯è§†åŒ–"""
        print(f"\nğŸ¯ è¯„ä¼°å‘¨æœŸ {self.n_calls} - å¼€å§‹å¯è§†åŒ–...")

        # ç”Ÿæˆæµ‹è¯•è½¨è¿¹
        num_test_trajectories = 3
        test_results = []

        for i in range(num_test_trajectories):
            # ç”Ÿæˆéšæœºèµ·ç‚¹å’Œç»ˆç‚¹
            start_tcp = self._sample_random_position()
            goal_tcp = self._sample_random_position()

            # ä½¿ç”¨RRT*è§„åˆ’è·¯å¾„
            try:
                waypoints = self.visualizer.visualize_rrt_star_planning(
                    start_tcp, goal_tcp,
                    show_tree=False,
                    save_path=f"eval_trajectory_{self.n_calls}_{i+1}.png"
                )
                test_results.append({
                    'start': start_tcp,
                    'goal': goal_tcp,
                    'waypoints': waypoints,
                    'success': waypoints is not None
                })
            except Exception as e:
                print(f"   âŒ è½¨è¿¹ {i+1} è§„åˆ’å¤±è´¥: {e}")
                test_results.append({
                    'start': start_tcp,
                    'goal': goal_tcp,
                    'waypoints': None,
                    'success': False
                })

        # ç»Ÿè®¡æˆåŠŸç‡
        success_count = sum(1 for r in test_results if r['success'])
        success_rate = success_count / len(test_results) * 100

        print(f"ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        print(f"   âœ… æˆåŠŸè½¨è¿¹: {success_count}/{len(test_results)} ({success_rate:.1f}%)")
        print(f"   ğŸ“¸ ç”Ÿæˆäº† {len(test_results)} ä¸ªå¯è§†åŒ–å›¾ç‰‡")

        # è®°å½•åˆ°tensorboard
        if hasattr(self, 'logger'):
            self.logger.record("eval/trajectory_planning_success_rate", success_rate)
            self.logger.record("eval/test_trajectories", len(test_results))

    def _sample_random_position(self) -> np.ndarray:
        """é‡‡æ ·éšæœºä½ç½®"""
        # UR10eå·¥ä½œç©ºé—´è¾¹ç•Œ
        return np.array([
            np.random.uniform(-0.5, 0.5),  # x
            np.random.uniform(-0.5, 0.5),  # y
            np.random.uniform(0.2, 0.7)    # z
        ])


def create_visualization_env(config_path: str, num_envs: int = 1):
    """åˆ›å»ºå¸¦å¯è§†åŒ–çš„ç¯å¢ƒ"""
    def _init():
        # å¯ç”¨å¯è§†åŒ–
        config = _load_config(config_path)

        # ä¸´æ—¶å¯ç”¨å¯è§†åŒ–
        original_vis = config.get('visualization', {}).get('enable', False)
        config['visualization']['enable'] = True

        env = UR10eTrajectoryEnv(
            config_path=config_path,
            num_envs=num_envs,
            mode="trajectory_tracking"
        )

        # æ¢å¤åŸå§‹è®¾ç½®
        if not original_vis:
            config['visualization']['enable'] = False

        env = Monitor(env, filename="./trajectory_monitor_logs/")
        return env
    return _init


def _load_config(config_path: str) -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        return config
    except FileNotFoundError:
        print(f"âŒ Config file {config_path} not found")
        return {}


def train_with_visualization(config_path: str = "config.yaml"):
    """å¸¦å¯è§†åŒ–çš„ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸ¨ UR10e è½¨è¿¹è·Ÿè¸ªè®­ç»ƒ - å¸¦å®æ—¶å¯è§†åŒ–")
    print("=" * 60)

    # åŠ è½½é…ç½®
    config = _load_config(config_path)

    # åˆ›å»ºå¯è§†åŒ–å·¥å…·
    visualizer = TrajectoryVisualizer(config_path)

    print(f"\nğŸ¬ åˆå§‹åŒ–å¯è§†åŒ–ç³»ç»Ÿ...")

    # é¦–å…ˆæ¼”ç¤ºRRT*è§„åˆ’å¯è§†åŒ–
    print("\n1. ğŸ¯ æ¼”ç¤ºRRT*è·¯å¾„è§„åˆ’å¯è§†åŒ–...")
    start_pos = np.array([0.4, 0.3, 0.5])
    goal_pos = np.array([-0.3, -0.2, 0.6])

    waypoints = visualizer.visualize_rrt_star_planning(
        start_pos, goal_pos,
        show_tree=True,
        save_path="demo_rrt_star_planning.png"
    )

    # è·å–ç¯å¢ƒæ•°é‡é…ç½®
    num_envs = config.get('env', {}).get('num_envs', 1)
    print(f"\nğŸš€ åˆ›å»º {num_envs} ä¸ªè®­ç»ƒç¯å¢ƒ...")

    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ (å¯è§†åŒ–æ¨¡å¼ä¸‹é€šå¸¸ä½¿ç”¨å•ç¯å¢ƒ)
    env_fn = create_visualization_env(config_path, num_envs)
    train_env = DummyVecEnv([env_fn])  # ä¸ºäº†å¯è§†åŒ–ç¨³å®šæ€§ï¼Œä½¿ç”¨å•ç¯å¢ƒ

    # åˆ›å»ºPPOæ¨¡å‹
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    ppo_config = config.get('ppo', {})

    model = PPO(
        policy="MlpPolicy",
        env=train_env,
        learning_rate=ppo_config.get('learning_rate', 3.0e-4),
        n_steps=ppo_config.get('n_steps', 2048),
        batch_size=ppo_config.get('batch_size', 64),
        n_epochs=ppo_config.get('n_epochs', 10),
        gamma=ppo_config.get('gamma', 0.995),
        tensorboard_log="./tensorboard_logs/",
        verbose=1,
        device=str(device)
    )

    print(f"ğŸ§  PPOæ¨¡å‹å·²åˆ›å»ºï¼Œè®¾å¤‡: {device}")

    # åˆ›å»ºå¯è§†åŒ–å›è°ƒ
    viz_callback = VisualizationCallback(
        visualizer=visualizer,
        eval_freq=10000,  # æ¯10Kæ­¥è¯„ä¼°ä¸€æ¬¡
        verbose=1
    )
    viz_callback.training_total_timesteps = config.get('ppo', {}).get('total_timesteps', 1000000)

    # è·å–è®­ç»ƒå‚æ•°
    total_timesteps = config.get('ppo', {}).get('total_timesteps', 1000000)

    print(f"\nğŸ‹ï¸  å¼€å§‹å¯è§†åŒ–è®­ç»ƒ:")
    print(f"   æ€»æ­¥æ•°: {total_timesteps:,}")
    print(f"   å¯è§†åŒ–é¢‘ç‡: æ¯10,000æ­¥")
    print(f"   è¯„ä¼°è½¨è¿¹æ•°: 3ä¸ª/æ¬¡")

    try:
        # æµ‹è¯•ç¯å¢ƒ
        print("ğŸ§ª æµ‹è¯•ç¯å¢ƒ...")
        obs = train_env.reset()
        action = train_env.action_space.sample()
        obs, reward, done, info = train_env.step(action)
        print(f"   ç¯å¢ƒæµ‹è¯•æˆåŠŸï¼Œå¥–åŠ±: {reward:.4f}")

        print("âœ… ç¯å¢ƒæµ‹è¯•é€šè¿‡ï¼Œå¼€å§‹è®­ç»ƒ...")

        # å¼€å§‹è®­ç»ƒ
        start_time = time.time()

        model.learn(
            total_timesteps=total_timesteps,
            log_interval=100,
            tb_log_name="trajectory_tracking_with_viz",
            callback=[viz_callback],
            progress_bar=True
        )

        training_time = time.time() - start_time

        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {training_time/3600:.2f} å°æ—¶")
        print(f"   å¹³å‡é€Ÿåº¦: {total_timesteps/training_time:.1f} æ­¥/ç§’")

        # æœ€ç»ˆå¯è§†åŒ–
        print(f"\nğŸ¨ ç”Ÿæˆæœ€ç»ˆè½¨è¿¹å¯è§†åŒ–...")
        visualizer.real_time_robot_visualization(num_trajectories=5)

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        visualizer.generate_analysis_report("final_analysis_report.html")

        # ä¿å­˜æ¨¡å‹
        model_save_path = f"trajectory_model_with_viz_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        model.save(model_save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_save_path}")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†
        train_env.close()
        print("ğŸ è®­ç»ƒä¼šè¯ç»“æŸ")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="UR10e å¸¦å¯è§†åŒ–çš„è½¨è¿¹è·Ÿè¸ªè®­ç»ƒ")
    parser.add_argument("--config", type=str, default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--demo-only", action="store_true", help="åªè¿è¡Œå¯è§†åŒ–æ¼”ç¤ºï¼Œä¸è®­ç»ƒ")

    args = parser.parse_args()

    if args.demo_only:
        # åªè¿è¡Œå¯è§†åŒ–æ¼”ç¤º
        print("ğŸ¨ åªè¿è¡Œå¯è§†åŒ–æ¼”ç¤ºæ¨¡å¼...")
        visualizer = TrajectoryVisualizer(args.config)

        # æ¼”ç¤ºRRT*è§„åˆ’
        start_pos = np.array([0.4, 0.3, 0.5])
        goal_pos = np.array([-0.3, -0.2, 0.6])
        visualizer.visualize_rrt_star_planning(start_pos, goal_pos, show_tree=True)

        # æ¼”ç¤ºæœºå™¨äººè½¨è¿¹
        visualizer.real_time_robot_visualization(num_trajectories=3)

        print("âœ… å¯è§†åŒ–æ¼”ç¤ºå®Œæˆ!")
    else:
        # å®Œæ•´è®­ç»ƒ
        train_with_visualization(args.config)